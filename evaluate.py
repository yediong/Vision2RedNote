import os
import json
import torch
import logging
import numpy as np
from tqdm import tqdm
from typing import List, Tuple, Dict, Any, Optional, Union
from PIL import Image
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sentence_transformers import SentenceTransformer
from scipy.spatial.distance import cosine
import warnings
warnings.filterwarnings('ignore')

from transformers import (
    Qwen2VLForConditionalGeneration,
    AutoProcessor
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Emojiè¡¨æƒ…åº“ - å°çº¢ä¹¦é£æ ¼
EMOJI_POOL = [
    "âœ¨", "ğŸ’•", "ğŸ’–", "ğŸ’", "ğŸ’—", "ğŸ’“", "ğŸ’", "ğŸ’Ÿ", "ğŸ’Œ", "ğŸ’‹",
    "ğŸŒ¸", "ğŸŒº", "ğŸŒ·", "ğŸŒ¹", "ğŸŒ»", "ğŸŒ¼", "ğŸŒ¿", "ğŸ€", "ğŸŒ±", "ï¿½ï¿½",
    "ï¿½ï¿½", "â­", "ğŸ’«", "ğŸŒ™", "â˜€ï¸", "ï¿½ï¿½", "â˜ï¸", "ğŸŒ¤ï¸", "ğŸŒ¥ï¸", "ï¿½ï¿½ï¸",
    "ğŸ€", "ğŸˆ", "ğŸ‰", "ğŸŠ", "ğŸ‹", "ğŸ", "ğŸ", "ğŸ", "ğŸ", "ğŸ€",
    "ğŸ’", "ğŸ’", "ğŸ’", "ğŸ’’", "ğŸ’“", "ğŸ’”", "ğŸ’•", "ğŸ’–", "ğŸ’—", "ğŸ’˜",
    "ğŸ˜", "ğŸ¥°", "ğŸ˜˜", "ğŸ˜‹", "ğŸ˜Š", "ğŸ˜‰", "ğŸ˜Œ", "ğŸ˜‡", "ğŸ¤—", "ğŸ¤©",
    "ğŸ”¥", "ğŸ’¯", "ğŸ’ª", "ğŸ‘", "ğŸ™Œ", "ğŸ¤", "ğŸ‘", "ğŸ‘Œ", "âœŒï¸", "ğŸ¤",
    "ğŸ¯", "ğŸª", "ğŸ¨", "ğŸ­", "ğŸ¬", "ğŸ¤", "ğŸ§", "ğŸµ", "ï¿½ï¿½", "ï¿½ï¿½"
]

class MetricsCalculator:
    """è®¡ç®—å„ç§è¯„ä¼°æŒ‡æ ‡"""
    
    def __init__(self):
        # åŠ è½½å¥å­åµŒå…¥æ¨¡å‹ç”¨äºè®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦
        try:
            # å°è¯•ä½¿ç”¨æœ¬åœ°æ¨¡å‹æˆ–å¤‡ç”¨æ¨¡å‹
            model_names = [
                'paraphrase-multilingual-MiniLM-L12-v2',
                'all-MiniLM-L6-v2',
                'distiluse-base-multilingual-cased-v2'
            ]
            
            self.sentence_model = None
            for model_name in model_names:
                try:
                    logger.info(f"å°è¯•åŠ è½½å¥å­åµŒå…¥æ¨¡å‹: {model_name}")
                    self.sentence_model = SentenceTransformer(model_name)
                    logger.info(f"æˆåŠŸåŠ è½½å¥å­åµŒå…¥æ¨¡å‹: {model_name}")
                    break
                except Exception as e:
                    logger.warning(f"æ— æ³•åŠ è½½æ¨¡å‹ {model_name}: {e}")
                    continue
            
            if self.sentence_model is None:
                logger.warning("æ‰€æœ‰å¥å­åµŒå…¥æ¨¡å‹éƒ½æ— æ³•åŠ è½½ï¼Œå°†ä½¿ç”¨ç®€å•çš„æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—")
                
        except Exception as e:
            logger.warning(f"æ— æ³•åŠ è½½å¥å­åµŒå…¥æ¨¡å‹: {e}")
            self.sentence_model = None
    
    def calculate_text_similarity(self, pred_texts, true_texts):
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦"""
        if self.sentence_model is None:
            # ä½¿ç”¨ç®€å•çš„å­—ç¬¦çº§ç›¸ä¼¼åº¦ä½œä¸ºå¤‡ç”¨
            logger.info("ä½¿ç”¨å­—ç¬¦çº§ç›¸ä¼¼åº¦ä½œä¸ºå¤‡ç”¨æ–¹æ³•")
            similarities = []
            for pred_text, true_text in zip(pred_texts, true_texts):
                # è®¡ç®—å­—ç¬¦é‡å åº¦
                pred_chars = set(pred_text.lower())
                true_chars = set(true_text.lower())
                
                if len(pred_chars) == 0 or len(true_chars) == 0:
                    similarities.append(0.0)
                else:
                    intersection = len(pred_chars.intersection(true_chars))
                    union = len(pred_chars.union(true_chars))
                    similarity = intersection / union if union > 0 else 0.0
                    similarities.append(similarity)
            
            return np.array(similarities)
        
        try:
            # è®¡ç®—åµŒå…¥
            pred_embeddings = self.sentence_model.encode(pred_texts, convert_to_tensor=True)
            true_embeddings = self.sentence_model.encode(true_texts, convert_to_tensor=True)
            
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            similarities = []
            for pred_emb, true_emb in zip(pred_embeddings, true_embeddings):
                sim = 1 - cosine(pred_emb.cpu().numpy(), true_emb.cpu().numpy())
                similarities.append(sim)
            
            return np.array(similarities)
        except Exception as e:
            logger.warning(f"è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦æ—¶å‡ºé”™: {e}")
            # å›é€€åˆ°å­—ç¬¦çº§ç›¸ä¼¼åº¦
            return self.calculate_text_similarity(pred_texts, true_texts)
    
    def calculate_emoji_density(self, texts):
        """è®¡ç®—emojiå¯†åº¦"""
        emoji_counts = []
        for text in texts:
            count = sum(1 for char in text if ord(char) > 127 and char in EMOJI_POOL)
            emoji_counts.append(count / len(text) if len(text) > 0 else 0)
        return np.array(emoji_counts)
    
    def calculate_length_metrics(self, pred_texts, true_texts):
        """è®¡ç®—é•¿åº¦ç›¸å…³æŒ‡æ ‡"""
        pred_lengths = [len(text) for text in pred_texts]
        true_lengths = [len(text) for text in true_texts]
        
        length_mae = mean_absolute_error(true_lengths, pred_lengths)
        length_mse = mean_squared_error(true_lengths, pred_lengths)
        length_rmse = np.sqrt(length_mse)
        
        return {
            'length_mae': length_mae,
            'length_mse': length_mse,
            'length_rmse': length_rmse,
            'pred_lengths': pred_lengths,
            'true_lengths': true_lengths
        }
    
    def calculate_xiaohongshu_style_score(self, texts):
        """è®¡ç®—å°çº¢ä¹¦é£æ ¼å¾—åˆ†"""
        style_scores = []
        for text in texts:
            score = 0
            
            # Emojiå¯†åº¦å¾—åˆ† (0-30åˆ†)
            emoji_count = sum(1 for char in text if ord(char) > 127 and char in EMOJI_POOL)
            emoji_density = emoji_count / len(text) if len(text) > 0 else 0
            score += min(30, emoji_density * 100)
            
            # å°çº¢ä¹¦è¯æ±‡å¾—åˆ† (0-25åˆ†)
            xiaohongshu_words = ["ç»äº†", "å¤ªå¯äº†", "ç¥ä»™", "å®è—", "ç»ç¾", "è¶…çˆ±", "çˆ±äº†çˆ±äº†", 
                                "ç§è‰", "å®‰åˆ©", "æ¨è", "åˆ†äº«", "æˆ‘çš„", "æˆ‘è§‰å¾—", "å¿ƒåŠ¨"]
            word_count = sum(1 for word in xiaohongshu_words if word in text)
            score += min(25, word_count * 5)
            
            # æ„Ÿå¹å·å¾—åˆ† (0-15åˆ†)
            exclamation_count = text.count('ï¼') + text.count('!')
            score += min(15, exclamation_count * 3)
            
            # é•¿åº¦é€‚ä¸­å¾—åˆ† (0-15åˆ†)
            if 20 <= len(text) <= 200:
                score += 15
            elif 10 <= len(text) <= 300:
                score += 10
            else:
                score += max(0, 15 - abs(len(text) - 100) / 10)
            
            # æƒ…æ„Ÿè¯æ±‡å¾—åˆ† (0-15åˆ†)
            emotion_words = ["å–œæ¬¢", "çˆ±", "å¿ƒåŠ¨", "ç¾", "å¥½çœ‹", "æ¼‚äº®", "å¯çˆ±", "æ£’", "å¥½"]
            emotion_count = sum(1 for word in emotion_words if word in text)
            score += min(15, emotion_count * 3)
            
            style_scores.append(score)
        
        return np.array(style_scores)
    
    def calculate_diversity_metrics(self, texts):
        """è®¡ç®—å¤šæ ·æ€§æŒ‡æ ‡"""
        if not texts:
            return {'unique_ratio': 0, 'vocab_diversity': 0, 'length_diversity': 0}
        
        # å”¯ä¸€æ€§æ¯”ä¾‹
        unique_texts = set(texts)
        unique_ratio = len(unique_texts) / len(texts)
        
        # è¯æ±‡å¤šæ ·æ€§
        all_words = []
        for text in texts:
            words = text.split()
            all_words.extend(words)
        
        vocab_size = len(set(all_words))
        total_words = len(all_words)
        vocab_diversity = vocab_size / total_words if total_words > 0 else 0
        
        # é•¿åº¦å¤šæ ·æ€§
        lengths = [len(text) for text in texts]
        length_diversity = np.std(lengths) / np.mean(lengths) if np.mean(lengths) > 0 else 0
        
        return {
            'unique_ratio': unique_ratio,
            'vocab_diversity': vocab_diversity,
            'length_diversity': length_diversity
        }
    
    def calculate_fluency_metrics(self, texts):
        """è®¡ç®—æµç•…æ€§æŒ‡æ ‡"""
        fluency_scores = []
        for text in texts:
            score = 0
            
            # æ ‡ç‚¹ç¬¦å·ä½¿ç”¨
            punctuation_count = sum(1 for char in text if char in 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š')
            score += min(20, punctuation_count * 2)
            
            # å¥å­å®Œæ•´æ€§
            if text.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '~', 'ï½')):
                score += 15
            
            # é•¿åº¦åˆç†æ€§
            if 10 <= len(text) <= 300:
                score += 25
            else:
                score += max(0, 25 - abs(len(text) - 100) / 10)
            
            # é‡å¤åº¦æƒ©ç½š
            words = text.split()
            if len(words) > 1:
                unique_words = set(words)
                repetition_ratio = len(unique_words) / len(words)
                score += repetition_ratio * 20
            
            # ç‰¹æ®Šå­—ç¬¦æ¯”ä¾‹
            special_chars = sum(1 for char in text if ord(char) > 127)
            special_ratio = special_chars / len(text) if len(text) > 0 else 0
            if 0.1 <= special_ratio <= 0.3:  # åˆç†çš„ç‰¹æ®Šå­—ç¬¦æ¯”ä¾‹
                score += 20
            else:
                score += max(0, 20 - abs(special_ratio - 0.2) * 100)
            
            fluency_scores.append(score)
        
        return np.array(fluency_scores)
    
    def calculate_comprehensive_score(self, pred_texts, true_texts):
        """è®¡ç®—ç»¼åˆå¾—åˆ†"""
        # è·å–å„é¡¹æŒ‡æ ‡
        text_similarities = self.calculate_text_similarity(pred_texts, true_texts)
        emoji_densities = self.calculate_emoji_density(pred_texts)
        style_scores = self.calculate_xiaohongshu_style_score(pred_texts)
        fluency_scores = self.calculate_fluency_metrics(pred_texts)
        diversity_metrics = self.calculate_diversity_metrics(pred_texts)
        
        # è®¡ç®—ç»¼åˆå¾—åˆ† (0-100åˆ†)
        comprehensive_scores = []
        for i in range(len(pred_texts)):
            score = 0
            
            # æ–‡æœ¬ç›¸ä¼¼åº¦ (30åˆ†)
            score += text_similarities[i] * 30
            
            # å°çº¢ä¹¦é£æ ¼ (25åˆ†)
            score += style_scores[i] * 0.25  # å½’ä¸€åŒ–åˆ°25åˆ†
            
            # æµç•…æ€§ (20åˆ†)
            score += fluency_scores[i] * 0.2  # å½’ä¸€åŒ–åˆ°20åˆ†
            
            # Emojiå¯†åº¦ (15åˆ†)
            score += min(15, emoji_densities[i] * 100)
            
            # å¤šæ ·æ€§å¥–åŠ± (10åˆ†)
            score += diversity_metrics['unique_ratio'] * 10
            
            comprehensive_scores.append(score)
        
        return np.array(comprehensive_scores)

# åœ¨evaluate.pyä¸­ä¿®æ”¹æ¨ç†æ—¶çš„prompt
# ä¿®æ”¹evaluate_modelå‡½æ•°ï¼Œä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨
def evaluate_model(model_dir, json_path, output_dir="./evaluation_results"):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    logger.info(f"å¼€å§‹è¯„ä¼°æ¨¡å‹: {model_dir}")
    
    # åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨ - ä½¿ç”¨é‡åŒ–å‡å°‘æ˜¾å­˜
    model = Qwen2VLForConditionalGeneration.from_pretrained(
        model_dir,
        device_map="auto",
        trust_remote_code=True,
        torch_dtype=torch.float16,  # ä½¿ç”¨åŠç²¾åº¦å‡å°‘æ˜¾å­˜
        low_cpu_mem_usage=True  # å‡å°‘CPUå†…å­˜ä½¿ç”¨
    )
    processor = AutoProcessor.from_pretrained(model_dir, trust_remote_code=True)
    
    # åŠ è½½æ•°æ®é›†
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # ä½¿ç”¨éªŒè¯é›†è¿›è¡Œè¯„ä¼°
    eval_items = data['val']
    logger.info(f"è¯„ä¼°æ•°æ®é›†å¤§å°: {len(eval_items)}")
    
    # åˆå§‹åŒ–è¯„ä¼°å·¥å…·
    metrics_calculator = MetricsCalculator()
    
    # ç”Ÿæˆé¢„æµ‹
    pred_texts = []
    true_texts = []
    
    model.eval()
    
    # å‡å°‘è¯„ä¼°æ ·æœ¬æ•°é‡ï¼Œé¿å…æ˜¾å­˜ä¸è¶³
    eval_samples = min(50, len(eval_items))  # åªè¯„ä¼°å‰50ä¸ªæ ·æœ¬
    logger.info(f"å®é™…è¯„ä¼°æ ·æœ¬æ•°é‡: {eval_samples}")
    
    with torch.no_grad():
        for i, item in enumerate(tqdm(eval_items[:eval_samples], desc="ç”Ÿæˆé¢„æµ‹")):
            try:
                # æ¸…ç†GPUç¼“å­˜
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                
                # è·å–çœŸå®æ–‡æœ¬
                description = None
                possible_fields = ['raw_description', 'description', 'text', 'caption', 'content']
                for field in possible_fields:
                    if field in item:
                        description = item[field]
                        break
                
                if description is None:
                    continue
                
                true_texts.append(description)
                
                # ç”Ÿæˆé¢„æµ‹æ–‡æœ¬
                image_path = item['image_path'].replace('\\', '/')
                if not os.path.exists(image_path):
                    image_path = os.path.join("data", os.path.basename(image_path))
                
                if not os.path.exists(image_path):
                    continue
                
                # ä¼˜åŒ–å›¾åƒåŠ è½½å’Œå¤„ç†
                try:
                    image = Image.open(image_path).convert('RGB')
                    # è°ƒæ•´å›¾åƒå¤§å°ï¼Œå‡å°‘æ˜¾å­˜ä½¿ç”¨
                    image.thumbnail((512, 512), Image.Resampling.LANCZOS)
                except Exception as e:
                    logger.warning(f"å›¾åƒåŠ è½½å¤±è´¥ {image_path}: {e}")
                    continue
                
                # æ„å»ºè¾“å…¥ - ä½¿ç”¨æ›´è‡ªç„¶çš„prompt
                messages = [
                    {
                        "role": "user",
                        "content": [
                            {"type": "image"},
                            {"type": "text", "text": "è¯·ç”¨å°çº¢ä¹¦åšä¸»çš„è¯­æ°”æè¿°è¿™å¼ å›¾ç‰‡ï¼Œè¦æ´»æ³¼å¯çˆ±ï¼Œå¤šç”¨emojiè¡¨æƒ…ï¼âœ¨"}
                        ],
                    }
                ]
                
                # å‡†å¤‡è¾“å…¥
                prompt = processor.apply_chat_template(
                    messages, tokenize=False, add_generation_prompt=True
                )
                
                inputs = processor(
                    text=prompt,
                    images=image,
                    return_tensors="pt",
                    padding=True
                ).to(model.device)
                
                # ç”Ÿæˆæè¿° - ä¼˜åŒ–ç”Ÿæˆå‚æ•°ï¼Œå‡å°‘æ˜¾å­˜ä½¿ç”¨
                generated_ids = model.generate(
                    **inputs, 
                    max_new_tokens=128,  # å‡å°‘ç”Ÿæˆé•¿åº¦
                    do_sample=True,
                    temperature=0.8,
                    top_p=0.9,
                    top_k=50,
                    repetition_penalty=1.1,
                    pad_token_id=processor.tokenizer.eos_token_id,
                    eos_token_id=processor.tokenizer.eos_token_id,
                    use_cache=False  # ç¦ç”¨ç¼“å­˜å‡å°‘æ˜¾å­˜
                )
                
                # è§£ç è¾“å‡º
                generated_ids_trimmed = [
                    out_ids[len(in_ids):] 
                    for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
                ]
                output_text = processor.tokenizer.batch_decode(
                    generated_ids_trimmed, 
                    skip_special_tokens=True, 
                    clean_up_tokenization_spaces=False
                )
                
                pred_texts.append(output_text[0])
                
                # åˆ é™¤ä¸­é—´å˜é‡ï¼Œé‡Šæ”¾æ˜¾å­˜
                del inputs, generated_ids, generated_ids_trimmed, output_text
                
            except Exception as e:
                logger.warning(f"ç”Ÿæˆé¢„æµ‹æ—¶å‡ºé”™: {e}")
                # æ¸…ç†æ˜¾å­˜
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                continue
    
    if len(pred_texts) == 0:
        logger.error("æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•é¢„æµ‹")
        return
    
    logger.info(f"æˆåŠŸç”Ÿæˆ {len(pred_texts)} ä¸ªé¢„æµ‹")
    
    # è®¡ç®—å„ç§æŒ‡æ ‡
    text_similarities = metrics_calculator.calculate_text_similarity(pred_texts, true_texts)
    emoji_densities = metrics_calculator.calculate_emoji_density(pred_texts)
    length_metrics = metrics_calculator.calculate_length_metrics(pred_texts, true_texts)
    style_scores = metrics_calculator.calculate_xiaohongshu_style_score(pred_texts)
    fluency_scores = metrics_calculator.calculate_fluency_metrics(pred_texts)
    diversity_metrics = metrics_calculator.calculate_diversity_metrics(pred_texts)
    comprehensive_scores = metrics_calculator.calculate_comprehensive_score(pred_texts, true_texts)
    
    # ä¿å­˜è¯„ä¼°æ•°æ®
    evaluation_data = {
        'text_similarities': text_similarities.tolist(),
        'emoji_densities': emoji_densities.tolist(),
        'true_lengths': length_metrics['true_lengths'],
        'pred_lengths': length_metrics['pred_lengths'],
        'length_mae': length_metrics['length_mae'],
        'length_mse': length_metrics['length_mse'],
        'length_rmse': length_metrics['length_rmse'],
        'style_scores': style_scores.tolist(),
        'fluency_scores': fluency_scores.tolist(),
        'diversity_metrics': diversity_metrics,
        'comprehensive_scores': comprehensive_scores.tolist(),
        'pred_texts': pred_texts,
        'true_texts': true_texts
    }
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¿å­˜è¯„ä¼°æ•°æ®ä¸ºJSONæ–‡ä»¶
    evaluation_data_path = os.path.join(output_dir, 'evaluation_data.json')
    with open(evaluation_data_path, 'w', encoding='utf-8') as f:
        json.dump(evaluation_data, f, indent=2, ensure_ascii=False)
    
    # æ‰“å°ä¸»è¦æŒ‡æ ‡
    logger.info("=" * 50)
    logger.info("è¯„ä¼°ç»“æœæ‘˜è¦:")
    logger.info(f"æ–‡æœ¬ç›¸ä¼¼åº¦å‡å€¼: {np.mean(text_similarities):.4f}")
    logger.info(f"Emojiå¯†åº¦å‡å€¼: {np.mean(emoji_densities):.4f}")
    logger.info(f"é£æ ¼å¾—åˆ†å‡å€¼: {np.mean(style_scores):.2f}")
    logger.info(f"æµç•…æ€§å¾—åˆ†å‡å€¼: {np.mean(fluency_scores):.2f}")
    logger.info(f"ç»¼åˆå¾—åˆ†å‡å€¼: {np.mean(comprehensive_scores):.2f}")
    logger.info(f"é•¿åº¦MAE: {length_metrics['length_mae']:.2f}")
    logger.info("=" * 50)
    
    logger.info(f"è¯„ä¼°å®Œæˆï¼æ•°æ®å·²ä¿å­˜åˆ°: {evaluation_data_path}")

# æ·»åŠ ä¸€ä¸ªè½»é‡çº§è¯„ä¼°å‡½æ•°
def quick_evaluate(model_dir, json_path, num_samples=20):
    """å¿«é€Ÿè¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼ˆä½¿ç”¨æ›´å°‘çš„æ ·æœ¬ï¼‰"""
    logger.info(f"å¿«é€Ÿè¯„ä¼°æ¨¡å‹: {model_dir}")
    
    # åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
    model = Qwen2VLForConditionalGeneration.from_pretrained(
        model_dir,
        device_map="auto",
        trust_remote_code=True,
        torch_dtype=torch.float16,
        low_cpu_mem_usage=True
    )
    processor = AutoProcessor.from_pretrained(model_dir, trust_remote_code=True)
    
    # åŠ è½½æ•°æ®é›†
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    eval_items = data['val'][:num_samples]  # åªä½¿ç”¨å‰num_samplesä¸ªæ ·æœ¬
    logger.info(f"å¿«é€Ÿè¯„ä¼°æ ·æœ¬æ•°é‡: {len(eval_items)}")
    
    # ç”Ÿæˆé¢„æµ‹
    pred_texts = []
    true_texts = []
    
    model.eval()
    with torch.no_grad():
        for i, item in enumerate(tqdm(eval_items, desc="å¿«é€Ÿè¯„ä¼°")):
            try:
                # æ¸…ç†GPUç¼“å­˜
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                
                # è·å–çœŸå®æ–‡æœ¬
                description = None
                possible_fields = ['raw_description', 'description', 'text', 'caption', 'content']
                for field in possible_fields:
                    if field in item:
                        description = item[field]
                        break
                
                if description is None:
                    continue
                
                true_texts.append(description)
                
                # ç”Ÿæˆé¢„æµ‹æ–‡æœ¬
                image_path = item['image_path'].replace('\\', '/')
                if not os.path.exists(image_path):
                    image_path = os.path.join("data", os.path.basename(image_path))
                
                if not os.path.exists(image_path):
                    continue
                
                image = Image.open(image_path).convert('RGB')
                image.thumbnail((512, 512), Image.Resampling.LANCZOS)
                
                # æ„å»ºè¾“å…¥
                messages = [
                    {
                        "role": "user",
                        "content": [
                            {"type": "image"},
                            {"type": "text", "text": "è¯·ç”¨å°çº¢ä¹¦åšä¸»çš„è¯­æ°”æè¿°è¿™å¼ å›¾ç‰‡ï¼Œè¦æ´»æ³¼å¯çˆ±ï¼Œå¤šç”¨emojiè¡¨æƒ…ï¼âœ¨"}
                        ],
                    }
                ]
                
                prompt = processor.apply_chat_template(
                    messages, tokenize=False, add_generation_prompt=True
                )
                
                inputs = processor(
                    text=prompt,
                    images=image,
                    return_tensors="pt",
                    padding=True
                ).to(model.device)
                
                # ç”Ÿæˆæè¿°
                generated_ids = model.generate(
                    **inputs, 
                    max_new_tokens=100,  # æ›´çŸ­çš„ç”Ÿæˆé•¿åº¦
                    do_sample=True,
                    temperature=0.8,
                    top_p=0.9,
                    top_k=50,
                    repetition_penalty=1.1,
                    pad_token_id=processor.tokenizer.eos_token_id,
                    use_cache=False
                )
                
                # è§£ç è¾“å‡º
                generated_ids_trimmed = [
                    out_ids[len(in_ids):] 
                    for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
                ]
                output_text = processor.tokenizer.batch_decode(
                    generated_ids_trimmed, 
                    skip_special_tokens=True, 
                    clean_up_tokenization_spaces=False
                )
                
                pred_texts.append(output_text[0])
                
                # åˆ é™¤ä¸­é—´å˜é‡
                del inputs, generated_ids, generated_ids_trimmed, output_text
                
            except Exception as e:
                logger.warning(f"ç”Ÿæˆé¢„æµ‹æ—¶å‡ºé”™: {e}")
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                continue
    
    if len(pred_texts) == 0:
        logger.error("æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•é¢„æµ‹")
        return
    
    # è®¡ç®—ç®€å•æŒ‡æ ‡
    metrics_calculator = MetricsCalculator()
    emoji_densities = metrics_calculator.calculate_emoji_density(pred_texts)
    style_scores = metrics_calculator.calculate_xiaohongshu_style_score(pred_texts)
    
    # æ‰“å°ç»“æœ
    logger.info("=" * 50)
    logger.info("å¿«é€Ÿè¯„ä¼°ç»“æœ:")
    logger.info(f"Emojiå¯†åº¦å‡å€¼: {np.mean(emoji_densities):.4f}")
    logger.info(f"é£æ ¼å¾—åˆ†å‡å€¼: {np.mean(style_scores):.2f}")
    logger.info("=" * 50)
    
    # æ˜¾ç¤ºå‡ ä¸ªç¤ºä¾‹
    logger.info("ç”Ÿæˆç¤ºä¾‹:")
    for i in range(min(3, len(pred_texts))):
        logger.info(f"é¢„æµ‹ {i+1}: {pred_texts[i]}")
        logger.info(f"çœŸå® {i+1}: {true_texts[i]}")
        logger.info("-" * 30)

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='è¯„ä¼°å°çº¢ä¹¦é£æ ¼å›¾åƒæè¿°æ¨¡å‹')
    parser.add_argument('--model_dir', type=str, default="./qwen2-finetuned0824_3",
                       help='æ¨¡å‹ç›®å½•è·¯å¾„')
    parser.add_argument('--json_path', type=str, default="data/qwen_vl_descriptions.json",
                       help='æ•°æ®é›†JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--quick', action='store_true',
                       help='ä½¿ç”¨å¿«é€Ÿè¯„ä¼°æ¨¡å¼ï¼ˆæ›´å°‘çš„æ ·æœ¬ï¼‰')
    parser.add_argument('--samples', type=int, default=20,
                       help='å¿«é€Ÿè¯„ä¼°æ—¶çš„æ ·æœ¬æ•°é‡')
    
    args = parser.parse_args()
    
    if args.quick:
        # å¿«é€Ÿè¯„ä¼°
        quick_evaluate(args.model_dir, args.json_path, args.samples)
    else:
        # å®Œæ•´è¯„ä¼°
        evaluate_model(args.model_dir, args.json_path)